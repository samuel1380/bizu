import express from 'express';
import cors from 'cors';
import { fileURLToPath } from 'url';
import { dirname, join } from 'path';
import { GoogleGenAI, HarmCategory, HarmBlockThreshold } from "@google/genai";

// --- CONFIGURA√á√ÉO DO AMBIENTE ---
const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

const app = express();
const PORT = process.env.PORT || 3000;

// --- LISTA DE MODELOS (FALLBACK AUTOM√ÅTICO - ORDEM DE PRIORIDADE) ---
// ATUALIZADO: Priorizando 1.5-Flash que √© o mais compat√≠vel (Free Tier e Paid).
// Adicionados modelos Pro e Legacy (1.0) como backup final.
const MODEL_FALLBACK_LIST = [
  "gemini-1.5-flash",       // O mais est√°vel e r√°pido atualmente
  "gemini-1.5-pro",         // Mais inteligente (Backup 1)
  "gemini-2.0-flash",       // Mais novo/Experimental (Backup 2)
  "gemini-1.5-flash-latest",
  "gemini-1.5-flash-001",
  "gemini-1.0-pro",         // Legado (Backup Final)
  "gemini-pro"              // Alias antigo
];

// Configura√ß√µes de seguran√ßa permissivas
const SAFETY_SETTINGS = [
  { category: HarmCategory.HARM_CATEGORY_HARASSMENT, threshold: HarmBlockThreshold.BLOCK_NONE },
  { category: HarmCategory.HARM_CATEGORY_HATE_SPEECH, threshold: HarmBlockThreshold.BLOCK_NONE },
  { category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, threshold: HarmBlockThreshold.BLOCK_NONE },
  { category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, threshold: HarmBlockThreshold.BLOCK_NONE },
];

// --- MIDDLEWARES ---
app.use(cors());
app.use(express.json());
app.use(express.static(join(__dirname, 'dist')));

// --- HELPERS ---

function cleanJSON(text) {
  if (!text) return "{}";
  return text.replace(/^```json\s*/, '').replace(/^```\s*/, '').replace(/\s*```$/, '').trim();
}

// Inicializa a IA com a chave do ambiente (Sempre l√™ a vari√°vel atual)
function getAI() {
  if (!process.env.API_KEY) {
    throw new Error("API_KEY_MISSING");
  }
  return new GoogleGenAI({ apiKey: process.env.API_KEY });
}

// --- FUN√á√ÉO "BLINDADA" DE EXECU√á√ÉO ---
// Tenta executar a a√ß√£o com o modelo preferido. Se der erro de modelo (404), tenta o pr√≥ximo.
async function runWithModelFallback(ai, actionCallback) {
  let lastError = null;

  // Se o usu√°rio definiu um modelo espec√≠fico no Render (AI_MODEL), tenta ele primeiro.
  // Se n√£o, usa a lista padr√£o expandida.
  const modelsToTry = process.env.AI_MODEL 
    ? [process.env.AI_MODEL, ...MODEL_FALLBACK_LIST] 
    : MODEL_FALLBACK_LIST;

  // Remove duplicatas
  const uniqueModels = [...new Set(modelsToTry)];

  for (const model of uniqueModels) {
    try {
      // console.log(`Tentando modelo: ${model}...`); // Debug (opcional)
      return await actionCallback(model);
    } catch (error) {
      // Se o erro for "Not Found" (404) ou problema de vers√£o do modelo, continua para o pr√≥ximo
      if (
        error.message && (
          error.message.includes("404") || 
          error.message.includes("not found") || 
          error.message.includes("not supported")
        )
      ) {
        console.warn(`‚ö†Ô∏è Modelo ${model} falhou ou indispon√≠vel para esta chave. Tentando pr√≥ximo...`);
        lastError = error;
        continue; 
      }
      
      // Se for outro erro (ex: quota 429, auth 401), lan√ßa imediatamente para n√£o perder tempo
      throw error;
    }
  }

  // Se todos falharem, o problema prov√°vel √© a Chave ou a API n√£o ativada no Google Cloud.
  console.error("‚ùå TODOS os modelos falharam. Verifique sua API Key.");
  throw new Error("Nenhum modelo compat√≠vel. Verifique se a 'Generative Language API' est√° ativada no Google Cloud Console para esta chave.");
}

// --- L√ìGICA DE NEG√ìCIO (ADAPTADA PARA RECEBER O NOME DO MODELO) ---

async function handleGenerateQuiz(ai, modelName, { topic, difficulty, numberOfQuestions }) {
  const prompt = `Gere um JSON array com ${numberOfQuestions} quest√µes de concurso sobre "${topic}" (N√≠vel: ${difficulty}).
  Formato obrigat√≥rio:
  [
    {
      "id": "uuid",
      "text": "Pergunta aqui?",
      "options": ["A", "B", "C", "D", "E"],
      "correctAnswerIndex": 0,
      "explanation": "Por que a resposta √© tal..."
    }
  ]`;
  
  const response = await ai.models.generateContent({
    model: modelName,
    contents: prompt,
    config: { responseMimeType: "application/json", safetySettings: SAFETY_SETTINGS }
  });
  
  return JSON.parse(cleanJSON(response.text));
}

async function handleAskTutor(ai, modelName, { history, message }) {
  const limitedHistory = (history || []).slice(-10);
  
  const chat = ai.chats.create({
    model: modelName,
    history: limitedHistory,
    config: {
      systemInstruction: "Voc√™ √© o BizuBot, mentor de concursos. Seja direto, motivador e use Markdown.",
      safetySettings: SAFETY_SETTINGS
    }
  });
  
  const result = await chat.sendMessage({ message });
  return { text: result.text };
}

async function handleGenerateMaterials(ai, modelName, { count }) {
  const prompt = `Sugira ${count} materiais de estudo para concursos p√∫blicos hoje.
  Retorne JSON Array:
  [
    {
      "title": "Titulo",
      "category": "Materia",
      "type": "ARTICLE", // ou PDF, VIDEO
      "duration": "10 min",
      "summary": "Resumo curto"
    }
  ]`;

  const response = await ai.models.generateContent({
    model: modelName,
    contents: prompt,
    config: { responseMimeType: "application/json", safetySettings: SAFETY_SETTINGS }
  });

  return JSON.parse(cleanJSON(response.text));
}

async function handleGenerateMaterialContent(ai, modelName, { material }) {
  const prompt = `Crie uma aula completa (formato Markdown) sobre: ${material.title} (${material.category}).`;
  
  const response = await ai.models.generateContent({
    model: modelName,
    contents: prompt,
    config: { safetySettings: SAFETY_SETTINGS }
  });

  return { content: response.text };
}

async function handleGenerateRoutine(ai, modelName, { targetExam, hours, subjects }) {
  const prompt = `Crie uma rotina semanal (JSON) para passar no concurso: ${targetExam}. 
  Disponibilidade: ${hours}h/dia. Mat√©rias: ${subjects}.
  Formato: { "weekSchedule": [ { "day": "Segunda", "focus": "...", "tasks": [{ "subject": "...", "activity": "...", "duration": "..." }] } ] }`;

  const response = await ai.models.generateContent({
    model: modelName,
    contents: prompt,
    config: { responseMimeType: "application/json", safetySettings: SAFETY_SETTINGS }
  });

  return JSON.parse(cleanJSON(response.text));
}

async function handleUpdateRadar(ai, modelName) {
  const prompt = `Liste 5 concursos previstos no Brasil (JSON Array).
  Campos: institution, title, forecast, status (Edital Publicado/Autorizado/Previsto), salary, board, url.`;

  const response = await ai.models.generateContent({
    model: modelName,
    contents: prompt,
    config: { responseMimeType: "application/json", safetySettings: SAFETY_SETTINGS }
  });

  return JSON.parse(cleanJSON(response.text));
}

// --- ROTAS DA API ---

app.post('/api/gemini', async (req, res) => {
  const { action, payload } = req.body;
  console.log(`[API] Recebendo a√ß√£o: ${action}`);

  try {
    const ai = getAI();
    let result;

    // Executa usando o sistema de fallback (tenta v√°rios modelos se necess√°rio)
    await runWithModelFallback(ai, async (modelName) => {
        switch (action) {
            case 'generateQuiz': 
                result = await handleGenerateQuiz(ai, modelName, payload); 
                break;
            case 'askTutor': 
                result = await handleAskTutor(ai, modelName, payload); 
                break;
            case 'generateMaterials': 
                result = await handleGenerateMaterials(ai, modelName, payload); 
                break;
            case 'generateMaterialContent': 
                result = await handleGenerateMaterialContent(ai, modelName, payload); 
                break;
            case 'generateRoutine': 
                result = await handleGenerateRoutine(ai, modelName, payload); 
                break;
            case 'updateRadar': 
                result = await handleUpdateRadar(ai, modelName); 
                break;
            default: 
                throw new Error("A√ß√£o desconhecida");
        }
    });

    res.json(result);

  } catch (error) {
    console.error(`[API] Erro CR√çTICO em ${action}:`, error);
    
    if (error.message === "API_KEY_MISSING") {
      return res.status(500).json({ error: "ERRO DE CONFIGURA√á√ÉO: Chave de API n√£o encontrada no servidor." });
    }
    
    if (error.message && error.message.includes("429")) {
      return res.status(429).json({ error: "Muitas requisi√ß√µes. A IA est√° ocupada, tente em 30 segundos." });
    }
    
    // Erro de modelo agora ser√° pego no loop, se chegar aqui √© porque todos falharam ou √© outro erro (ex: Auth)
    if (error.message && (error.message.includes("Generative Language API") || error.message.includes("Nenhum modelo compat√≠vel"))) {
         return res.status(404).json({ error: error.message });
    }
    
    if (error.message && (error.message.includes("404") || error.message.includes("not found"))) {
        return res.status(404).json({ error: "Erro de Conex√£o com IA (Modelo n√£o encontrado ou Chave inv√°lida)." });
    }

    res.status(500).json({ error: "Erro interno na IA. Tente novamente." });
  }
});

app.get('*', (req, res) => {
  res.sendFile(join(__dirname, 'dist', 'index.html'));
});

app.listen(PORT, () => {
  console.log(`‚úÖ SERVIDOR ONLINE NA PORTA ${PORT}`);
  
  if (process.env.API_KEY) {
    const maskedKey = process.env.API_KEY.substring(0, 5) + "...";
    console.log(`üîë API Key: ${maskedKey} (OK)`);
    console.log(`üõ°Ô∏è  Modelos dispon√≠veis (ordem de tentativa): ${MODEL_FALLBACK_LIST.join(', ')}`);
  } else {
    console.log(`‚ùå API Key: N√ÉO ENCONTRADA`);
  }
});
