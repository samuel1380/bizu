import express from 'express';
import cors from 'cors';
import { fileURLToPath } from 'url';
import { dirname, join } from 'path';
import { GoogleGenAI, HarmCategory, HarmBlockThreshold } from "@google/genai";

// --- CONFIGURA√á√ÉO DO AMBIENTE ---
const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

const app = express();
const PORT = process.env.PORT || 3000;

// --- LISTA DE MODELOS (PRIORIDADE GEMINI 3) ---
// Atualizado para usar os modelos mais recentes solicitados.
const MODEL_FALLBACK_LIST = [
  "gemini-3-flash-preview",   // Prioridade 1: Solicitado (Mais r√°pido/eficiente)
  "gemini-3-pro-preview",     // Prioridade 2: Maior capacidade de racioc√≠nio
  "gemini-2.0-flash-exp",     // Fallback: Vers√£o experimental recente
  "gemini-2.0-flash",         // Fallback: Vers√£o Flash 2.0
  "gemini-flash-latest"       // Fallback: Alias gen√©rico do Google (aponta para o mais est√°vel)
];

// Configura√ß√µes de seguran√ßa permissivas
const SAFETY_SETTINGS = [
  { category: HarmCategory.HARM_CATEGORY_HARASSMENT, threshold: HarmBlockThreshold.BLOCK_NONE },
  { category: HarmCategory.HARM_CATEGORY_HATE_SPEECH, threshold: HarmBlockThreshold.BLOCK_NONE },
  { category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, threshold: HarmBlockThreshold.BLOCK_NONE },
  { category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, threshold: HarmBlockThreshold.BLOCK_NONE },
];

// --- MIDDLEWARES ---
app.use(cors());
app.use(express.json());
app.use(express.static(join(__dirname, 'dist')));

// --- HELPERS ---

function cleanJSON(text) {
  if (!text) return "{}";
  return text.replace(/^```json\s*/, '').replace(/^```\s*/, '').replace(/\s*```$/, '').trim();
}

const sleep = (ms) => new Promise(r => setTimeout(r, ms));

// Inicializa a IA com a chave do ambiente
function getAI() {
  if (!process.env.API_KEY) {
    throw new Error("API_KEY_MISSING");
  }
  return new GoogleGenAI({ apiKey: process.env.API_KEY });
}

// --- FUN√á√ÉO "BLINDADA" DE EXECU√á√ÉO ---
async function runWithModelFallback(ai, actionCallback) {
  let lastError = null;

  // Se o usu√°rio definiu AI_MODEL manualmente, tenta ele primeiro.
  const modelsToTry = process.env.AI_MODEL 
    ? [process.env.AI_MODEL, ...MODEL_FALLBACK_LIST] 
    : MODEL_FALLBACK_LIST;

  const uniqueModels = [...new Set(modelsToTry)];

  for (const model of uniqueModels) {
    try {
      // console.log(`Tentando modelo: ${model}...`); 
      return await actionCallback(model);
    } catch (error) {
      const errorMessage = error.message || "";
      
      // 1. Erro de Modelo n√£o encontrado (404)
      if (errorMessage.includes("404") || errorMessage.includes("not found")) {
        console.warn(`‚ö†Ô∏è Modelo ${model} n√£o dispon√≠vel. Tentando pr√≥ximo...`);
        lastError = error;
        continue; 
      }

      // 2. Erro de Limite de Cota (429 - Resource Exhausted)
      if (errorMessage.includes("429") || errorMessage.includes("Quota exceeded") || errorMessage.includes("RESOURCE_EXHAUSTED")) {
        console.warn(`‚ö†Ô∏è Modelo ${model} ocupado (429). Aguardando 2s...`);
        await sleep(2000); 
        lastError = error;
        continue;
      }
      
      // Outros erros, lan√ßa direto
      throw error;
    }
  }

  // Se chegou aqui, falhou em todos
  console.error("‚ùå Todos os modelos falharam.");
  
  if (lastError && lastError.message.includes("429")) {
    throw new Error("O servidor da IA est√° sobrecarregado (Muitas requisi√ß√µes). Aguarde 30 segundos e tente novamente.");
  }
  
  throw new Error(`N√£o foi poss√≠vel conectar aos modelos Gemini 3 ou anteriores. Detalhe: ${lastError?.message}`);
}

// --- L√ìGICA DE NEG√ìCIO ---

async function handleGenerateQuiz(ai, modelName, { topic, difficulty, numberOfQuestions }) {
  const prompt = `Gere um JSON array com ${numberOfQuestions} quest√µes de concurso sobre "${topic}" (N√≠vel: ${difficulty}).
  Formato obrigat√≥rio:
  [
    {
      "id": "uuid",
      "text": "Pergunta aqui?",
      "options": ["A", "B", "C", "D", "E"],
      "correctAnswerIndex": 0,
      "explanation": "Por que a resposta √© tal..."
    }
  ]`;
  
  const response = await ai.models.generateContent({
    model: modelName,
    contents: prompt,
    config: { responseMimeType: "application/json", safetySettings: SAFETY_SETTINGS }
  });
  
  return JSON.parse(cleanJSON(response.text));
}

async function handleAskTutor(ai, modelName, { history, message }) {
  // Mant√©m hist√≥rico curto para evitar estouro de tokens
  const limitedHistory = (history || []).slice(-5);
  
  const chat = ai.chats.create({
    model: modelName,
    history: limitedHistory,
    config: {
      systemInstruction: "Voc√™ √© o BizuBot, mentor de concursos. Seja direto, motivador e use Markdown.",
      safetySettings: SAFETY_SETTINGS
    }
  });
  
  const result = await chat.sendMessage({ message });
  return { text: result.text };
}

async function handleGenerateMaterials(ai, modelName, { count }) {
  const prompt = `Sugira ${count} materiais de estudo para concursos p√∫blicos hoje.
  Retorne JSON Array:
  [
    {
      "title": "Titulo",
      "category": "Materia",
      "type": "ARTICLE", // ou PDF, VIDEO
      "duration": "10 min",
      "summary": "Resumo curto"
    }
  ]`;

  const response = await ai.models.generateContent({
    model: modelName,
    contents: prompt,
    config: { responseMimeType: "application/json", safetySettings: SAFETY_SETTINGS }
  });

  return JSON.parse(cleanJSON(response.text));
}

async function handleGenerateMaterialContent(ai, modelName, { material }) {
  const prompt = `Crie uma aula completa (formato Markdown) sobre: ${material.title} (${material.category}).`;
  
  const response = await ai.models.generateContent({
    model: modelName,
    contents: prompt,
    config: { safetySettings: SAFETY_SETTINGS }
  });

  return { content: response.text };
}

async function handleGenerateRoutine(ai, modelName, { targetExam, hours, subjects }) {
  const prompt = `Crie uma rotina semanal (JSON) para passar no concurso: ${targetExam}. 
  Disponibilidade: ${hours}h/dia. Mat√©rias: ${subjects}.
  Formato: { "weekSchedule": [ { "day": "Segunda", "focus": "...", "tasks": [{ "subject": "...", "activity": "...", "duration": "..." }] } ] }`;

  const response = await ai.models.generateContent({
    model: modelName,
    contents: prompt,
    config: { responseMimeType: "application/json", safetySettings: SAFETY_SETTINGS }
  });

  return JSON.parse(cleanJSON(response.text));
}

async function handleUpdateRadar(ai, modelName) {
  const prompt = `Liste 5 concursos previstos no Brasil (JSON Array).
  Campos: institution, title, forecast, status (Edital Publicado/Autorizado/Previsto), salary, board, url.`;

  const response = await ai.models.generateContent({
    model: modelName,
    contents: prompt,
    config: { responseMimeType: "application/json", safetySettings: SAFETY_SETTINGS }
  });

  return JSON.parse(cleanJSON(response.text));
}

// --- ROTAS DA API ---

app.post('/api/gemini', async (req, res) => {
  const { action, payload } = req.body;
  console.log(`[API] Recebendo a√ß√£o: ${action}`);

  try {
    const ai = getAI();
    let result;

    await runWithModelFallback(ai, async (modelName) => {
        switch (action) {
            case 'generateQuiz': result = await handleGenerateQuiz(ai, modelName, payload); break;
            case 'askTutor': result = await handleAskTutor(ai, modelName, payload); break;
            case 'generateMaterials': result = await handleGenerateMaterials(ai, modelName, payload); break;
            case 'generateMaterialContent': result = await handleGenerateMaterialContent(ai, modelName, payload); break;
            case 'generateRoutine': result = await handleGenerateRoutine(ai, modelName, payload); break;
            case 'updateRadar': result = await handleUpdateRadar(ai, modelName); break;
            default: throw new Error("A√ß√£o desconhecida");
        }
    });

    res.json(result);

  } catch (error) {
    console.error(`[API] Erro Final:`, error.message);
    
    if (error.message === "API_KEY_MISSING") {
      return res.status(500).json({ error: "ERRO DE CONFIGURA√á√ÉO: Chave de API n√£o encontrada." });
    }
    
    if (error.message.includes("servidor da IA est√° sobrecarregado")) {
      return res.status(429).json({ error: "Servidores ocupados. Aguarde alguns segundos." });
    }

    res.status(500).json({ error: error.message || "Erro interno na IA." });
  }
});

app.get('*', (req, res) => {
  res.sendFile(join(__dirname, 'dist', 'index.html'));
});

app.listen(PORT, () => {
  console.log(`‚úÖ SERVIDOR ONLINE NA PORTA ${PORT}`);
  console.log(`üõ°Ô∏è  Modelos Gemini 3 Ativados: ${MODEL_FALLBACK_LIST.join(', ')}`);
});
